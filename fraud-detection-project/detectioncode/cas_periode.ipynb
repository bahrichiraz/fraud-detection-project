{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id                 Type_fraude  id_numerique\n",
      "679   6740142023-02-07 16:29:49.526   fausse periode pour aesio    6740142023\n",
      "1802  6775722023-03-22 14:41:36.997   fausse periode pour aesio    6775722023\n",
      "1803  6775722023-03-22 14:41:45.455   fausse periode pour aesio    6775722023\n",
      "1804  6775722023-03-22 14:41:52.749   fausse periode pour aesio    6775722023\n",
      "1880  6778002023-03-24 15:27:51.006   fausse periode pour aesio    6778002023\n",
      "...                             ...                         ...           ...\n",
      "4875  6826242023-06-07 12:12:23.085  fausse periode pour acheel    6826242023\n",
      "4876  6826242023-06-07 12:12:27.941  fausse periode pour acheel    6826242023\n",
      "4877  6826292023-06-07 12:14:29.879  fausse periode pour acheel    6826292023\n",
      "4878  6826292023-06-07 12:14:35.452  fausse periode pour acheel    6826292023\n",
      "4879  6826292023-06-07 12:14:40.319  fausse periode pour acheel    6826292023\n",
      "\n",
      "[199 rows x 3 columns]\n",
      "No new records found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiraz\\AppData\\Local\\Temp\\ipykernel_18880\\2465623749.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result.loc[:, 'Type_fraude'] = \"fausse periode pour aesio\"\n",
      "C:\\Users\\chiraz\\AppData\\Local\\Temp\\ipykernel_18880\\2465623749.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_6_months.loc[:, 'Type_fraude'] = \"fausse periode pour acheel\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Connexion à la base de données\n",
    "def connect_db():\n",
    "    engine = create_engine('mysql+mysqlconnector://bahri_chiraz:wwZYY4s7cmw5@185.2.101.12/geoprod_stage_2024')\n",
    "    return engine\n",
    "\n",
    "def load_data(engine):\n",
    "  data_doss = pd.read_sql_query(\"SELECT id FROM etat_dossier WHERE classe != 2\", engine)\n",
    "  etats = ','.join([f\"'{ids}'\" for ids in data_doss['id']])\n",
    "\n",
    "  data_aff = pd.read_sql_query(f\"SELECT id, date_deff, date_creation FROM affaire WHERE status IN ({etats})\", engine)\n",
    "\n",
    "  data_aff['date_deff'] = pd.to_datetime(data_aff['date_deff'])\n",
    "  data_aff['date_creation'] = pd.to_datetime(data_aff['date_creation'])\n",
    "\n",
    "  data_aff['difference'] = (data_aff['date_deff'] - data_aff['date_creation']).dt.days\n",
    "\n",
    "  result = data_aff[data_aff['difference'] > 4 * 30]  # 4 mois * 30 jours\n",
    "  if not result.empty:\n",
    "    result.loc[:, 'Type_fraude'] = \"fausse periode pour aesio\"\n",
    "  result_6_months = data_aff[data_aff['difference'] > 6 * 30]  # 6 mois * 30 jours\n",
    "\n",
    "  if not result_6_months.empty:\n",
    "    result_6_months.loc[:, 'Type_fraude'] = \"fausse periode pour acheel\"\n",
    "\n",
    "# Concaténer les deux résultats\n",
    "  final_result = pd.concat([result[['id', 'Type_fraude']], result_6_months[['id', 'Type_fraude']]])\n",
    "  final_result['id_numerique'] = final_result['id'].apply(lambda x: int(x.split('-')[0]))\n",
    "\n",
    "  return final_result\n",
    "\n",
    "def scale_features(final_result):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(final_result[['id_numerique']])\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    return scaled_features\n",
    "\n",
    "# Identifier le nombre optimal de clusters en utilisant le graphique du coude\n",
    "def find_optimal_clusters(scaled_features):\n",
    "    range_clusters = range(1, 10)\n",
    "    variances = []\n",
    "    for n_clusters in range_clusters:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(scaled_features)\n",
    "        variances.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range_clusters, variances, marker='o')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Variance Explained')\n",
    "    plt.title('Elbow Plot')\n",
    "    plt.show()\n",
    "    \n",
    "    # Déterminer le nombre optimal de clusters visuellement (ici, 3 pour l'exemple)\n",
    "    optimal_n_clusters = 3\n",
    "    return optimal_n_clusters\n",
    "\n",
    "# Appliquer l'algorithme de clustering K-means\n",
    "def apply_kmeans(scaled_features, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(scaled_features)\n",
    "    joblib.dump(kmeans, 'kmeans_model.pkl')\n",
    "\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "# Traiter les nouvelles affaires et mettre à jour les clusters\n",
    "def process_new_affaires(new_affaires):\n",
    "    scaled_features = scale_features(new_affaires)\n",
    "    optimal_n_clusters = find_optimal_clusters(scaled_features)\n",
    "    clusters = apply_kmeans(scaled_features, optimal_n_clusters)\n",
    "    new_affaires['cluster'] = clusters\n",
    "    \n",
    "    tableau_final = new_affaires[['id', 'Type_fraude', 'cluster']]\n",
    "    tableau_final['Date_systeme'] = datetime.now()\n",
    "    tableau_final.to_csv('periode.csv', index=False)\n",
    "    \n",
    "    global processed_affair\n",
    "    processed_affair = pd.concat([processed_affair, new_affaires[['id']]], ignore_index=True)\n",
    "    \n",
    "    print(tableau_final)\n",
    "    return tableau_final\n",
    "\n",
    "def initialize_processed_affaire():\n",
    "    if 'processed_affair' not in globals():\n",
    "        global processed_affair\n",
    "        processed_affair = pd.DataFrame(columns=['id'])\n",
    "\n",
    "# Identifier les nouvelles affaires\n",
    "def identify_new_affaires(final_result):\n",
    "    new_affaires = final_result[~final_result['id'].isin(processed_affair['id'])]\n",
    "    return new_affaires\n",
    "\n",
    "def main():\n",
    "    engine = connect_db()\n",
    "    data_aff = load_data(engine)\n",
    "    initialize_processed_affaire()\n",
    "    new_affaires = identify_new_affaires(data_aff)\n",
    "    \n",
    "    if not new_affaires.empty:\n",
    "        print(f\"Found {len(new_affaires)} new records.\")\n",
    "        tableau_final = process_new_affaires(new_affaires)\n",
    "    else:\n",
    "        print(\"No new records found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
